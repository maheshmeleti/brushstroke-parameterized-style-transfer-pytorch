{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7434ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from einops import rearrange\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882f9294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from render_tools import renderer, sample_quadratic_bezier_curve\n",
    "from vgg import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2962f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.key_matrix = nn.Linear(1024, 256, bias=False)\n",
    "        self.query_matrix = nn.Linear(1024, 256, bias=False)\n",
    "        self.value_matrix = nn.Linear(1024, 256, bias=False)\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=256, num_heads=1)\n",
    "        self.out_matrix = nn.Linear(256, 1024, bias=False)\n",
    "    \n",
    "    def forward(self, content, style):\n",
    "        b, c, h, w = content.shape\n",
    "                        \n",
    "        content = rearrange(content, 'b c h w -> b c (h w)')\n",
    "        style = rearrange(style, 'b c h w -> b c (h w)')\n",
    "        \n",
    "        key = self.key_matrix(content)\n",
    "        query = self.query_matrix(style)\n",
    "        value = self.value_matrix(content)\n",
    "        \n",
    "        attn_output, attn_output_weights = self.multihead_attn(query, key, value)\n",
    "        out = self.out_matrix(attn_output)\n",
    "        out = rearrange(out, 'b c (h w) -> b c h w', h=h, w=w)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "578dd442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=False))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b65374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Up_Conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "                         nn.BatchNorm2d(out_channels),\n",
    "                         nn.ReLU(inplace=False))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3f2b738",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.block1 = Conv_Block(512, 256)\n",
    "        self.up1 = Up_Conv(256, 256)\n",
    "        \n",
    "        self.block2 = Conv_Block(256, 128)\n",
    "        self.up2 = Up_Conv(128, 128)\n",
    "        \n",
    "        self.block3 = Conv_Block(128, 64)\n",
    "        self.up3 = Up_Conv(64, 64)\n",
    "        \n",
    "        self.block4 = Conv_Block(64, 32)\n",
    "        self.up4 = Up_Conv(32, 32)\n",
    "        \n",
    "        self.final_block = Conv_Block(32, 12)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.up1(x)   # 32 -> 64\n",
    "        \n",
    "        x = self.block2(x)\n",
    "        x = self.up2(x)   # 64 -> 128\n",
    "        \n",
    "        x = self.block3(x)\n",
    "        #x = self.up3(x)   # 128 -> 256\n",
    "        \n",
    "        x = self.block4(x)\n",
    "        #x = self.up4(x)   # 32 -> 64\n",
    "        \n",
    "        out = self.final_block(x)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2e57bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(image_name, img_size, device):\n",
    "    loader = lambda imsize: transforms.Compose([\n",
    "    transforms.Resize((imsize,imsize)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std = [0.229, 0.224, 0.225])]) \n",
    "    \n",
    "    image = Image.open(image_name)\n",
    "    image = loader(img_size)(image).unsqueeze(0)\n",
    "    image = image.to(device, torch.float)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7b6db38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrushStrokeRenderer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.samples_per_curve = 10\n",
    "        self.canvas_height = 512\n",
    "        self.canvas_width =  512\n",
    "        self.strokes_per_pixel = 20\n",
    "        self.canvas_color = .5\n",
    "        \n",
    "    def forward(self, curve_s, curve_e, curve_c, location, color, width):\n",
    "        curve_points = sample_quadratic_bezier_curve(s=curve_s + location,\n",
    "                                                     e=curve_e + location,\n",
    "                                                     c=curve_c + location,\n",
    "                                                     num_points=self.samples_per_curve)\n",
    "        \n",
    "        canvas = renderer(curve_points, location, color, width,\n",
    "                                 self.canvas_height, self.canvas_width, self.strokes_per_pixel, self.canvas_color)\n",
    "        \n",
    "        return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "81cc7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        encoder = models.vgg16(pretrained=True).features\n",
    "\n",
    "        self.block_32x32 = nn.Sequential(*encoder[:27])\n",
    "        self.transformer = Transformer()\n",
    "        \n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "        self.renderer = BrushStrokeRenderer()\n",
    "        \n",
    "    def forward(self, content_img, style_img):\n",
    "        feats_content = self.block_32x32(content_img)\n",
    "        feats_style = self.block_32x32(style_img)\n",
    "        \n",
    "        out = self.transformer(feats_content, feats_style)\n",
    "        \n",
    "        out = self.decoder(out)\n",
    "        \n",
    "        # curve s [N x 2]\n",
    "        # curve e [N x 2]\n",
    "        # curve c [N x 2]\n",
    "        # color [N x 3]\n",
    "        # location [N x 2]\n",
    "        # width [N x 1]\n",
    "        # total 12 channels\n",
    "        #return out\n",
    "        \n",
    "        out = out.squeeze(0)\n",
    "        curve_s = rearrange(out[0:2], 'c h w -> (h w) c') \n",
    "        curve_e =  rearrange(out[2:4], 'c h w -> (h w) c')\n",
    "        curve_c =  rearrange(out[4:6], 'c h w -> (h w) c')\n",
    "        location =  rearrange(out[6:8], 'c h w -> (h w) c')\n",
    "        color =  rearrange(out[8:11], 'c h w -> (h w) c')\n",
    "        width = rearrange(out[11:12], 'c h w -> (h w) c')\n",
    "        \n",
    "#         print(curve_s.shape, curve_e.shape, curve_c.shape, location.shape, color.shape, width.shape)\n",
    "        \n",
    "        \n",
    "        canvas = self.renderer(curve_s, curve_e, curve_c, location, color, width)\n",
    "        \n",
    "        return canvas.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "05bec6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_img_file = '/scratch/umeleti/code/style/pytorch_brushstroke/brushstroke-parameterized-style-transfer/images/golden-gate-bridge.jpg'\n",
    "style_img_file = '/scratch/umeleti/code/style/pytorch_brushstroke/brushstroke-parameterized-style-transfer/images/starry_night.jpg'\n",
    "# vgg_weight_file = '/scratch/umeleti/code/style/pytorch_brushstroke/brushstroke-parameterized-style-transfer/vgg_weights/vgg19_weights_normalized.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea510823",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_img = image_loader(content_img_file, 512, device)\n",
    "style_img = image_loader(style_img_file, 512, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f0c2afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e1cc126d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384, 2]) torch.Size([16384, 2]) torch.Size([16384, 2]) torch.Size([16384, 2]) torch.Size([16384, 3]) torch.Size([16384, 1])\n"
     ]
    }
   ],
   "source": [
    "out = model(content_img, style_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e49c9e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 512, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(out..detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2dbb0ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16384, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(out_[11:12], 'c h w -> (h w) c').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d8a164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_s = out.squeeze(0)[10:11,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "370974c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8091a5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16384, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(curve_s, 'c h w -> (h w) c').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd74c08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3a3fbf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_[10:11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "152a2ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 128, 128])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90af37eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def give_vgg16_stages(self):\n",
    "\n",
    "#     block1 = nn.Sequential(*self.encoder[:6])  # outshape 128, 256, 256\n",
    "#     block2 = nn.Sequential(*self.encoder[6:13])  # 256, 128, 128\n",
    "#     block3 = nn.Sequential(*self.encoder[13:20])  # 512, 64, 64\n",
    "#     block4 = nn.Sequential(*self.encoder[20:27])  # 512, 32, 32\n",
    "#     block5 = nn.Sequential(*self.encoder[27:34]) # 512, 16, 16\n",
    "\n",
    "#     return [128, 256, 512, 512, 512], (block1, block2, block3, block4, block5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# canvas_height = 512 \n",
    "# canvas_width = 512\n",
    "# strokes_per_pixel = 20\n",
    "# canvas_color = .5\n",
    "# curve_points = torch.randint(0, canvas_height, (10000, 20, 2))\n",
    "# location = torch.randint(0, canvas_height, (10000,2))\n",
    "# color =  torch.randint(0, 1, (10000,3))\n",
    "# width = torch.randint((10000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e1df067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from tensorflow\n",
    "# num_strokes = 1000\n",
    "# canvas_height = 512\n",
    "# canvas_width = 512\n",
    "\n",
    "# width_scale=.1\n",
    "# sec_scale = 1.1\n",
    "# samples_per_curve = 10\n",
    "\n",
    "# color = np.random.rand(num_strokes, 3)\n",
    "\n",
    "# # Brushstroke widths\n",
    "# width = np.random.rand(num_strokes, 1) * width_scale\n",
    "\n",
    "# # Brushstroke locations\n",
    "# location = np.stack([np.random.rand(num_strokes) * canvas_height, np.random.rand(num_strokes) * canvas_width], axis=-1)\n",
    "\n",
    "# # Start point for the Bezier curves\n",
    "# s = np.stack([np.random.uniform(low=-1, high=1, size=num_strokes) * canvas_height,\n",
    "#               np.random.uniform(low=-1, high=1, size=num_strokes) * canvas_width], axis=-1)\n",
    "\n",
    "# # End point for the Bezier curves\n",
    "# e = np.stack([np.random.uniform(low=-1, high=1, size=num_strokes) * canvas_height,\n",
    "#               np.random.uniform(low=-1, high=1, size=num_strokes) * canvas_width], axis=-1)\n",
    "\n",
    "# # Control point for the Bezier curves\n",
    "# c = np.stack([np.random.uniform(low=-1, high=1, size=num_strokes) * canvas_height,\n",
    "#               np.random.uniform(low=-1, high=1, size=num_strokes) * canvas_width], axis=-1)\n",
    "\n",
    "# # Normalize control points\n",
    "# sec_center = (s + e + c) / 3.0\n",
    "# s, e, c = [x - sec_center for x in [s, e, c]]\n",
    "# s, e, c = [x * sec_scale for x in [s, e, c]]\n",
    "\n",
    "# curve_s = torch.nn.Parameter(torch.from_numpy(np.array(s, 'float32')), requires_grad=True)\n",
    "# curve_e = torch.nn.Parameter(torch.from_numpy(np.array(e, 'float32')), requires_grad=True)\n",
    "# curve_c = torch.nn.Parameter(torch.from_numpy(np.array(c, 'float32')), requires_grad=True)\n",
    "# color = torch.nn.Parameter(torch.from_numpy(np.array(color, 'float32')), requires_grad=True)\n",
    "# location = torch.nn.Parameter(torch.from_numpy(np.array(location, 'float32')), requires_grad=True)\n",
    "# width = torch.nn.Parameter(torch.from_numpy(np.array(width, 'float32')), requires_grad=True)\n",
    "\n",
    "# curve_points = sample_quadratic_bezier_curve(s=curve_s + location,\n",
    "#                                             e=curve_e + location,\n",
    "#                                             c=curve_c + location,\n",
    "#                                             num_points=samples_per_curve)\n",
    "\n",
    "# strokes_per_pixel=20\n",
    "# canvas_color = 0.5\n",
    "# canvas = renderer(curve_points, location, color, width,\n",
    "#                                  canvas_height, canvas_width, strokes_per_pixel, canvas_color)\n",
    "\n",
    "# plt.imshow(canvas.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6eaddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4058b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93ff3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "style",
   "language": "python",
   "name": "style"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
